{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bcd4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "\n",
    "import qml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Import from functions.py file\n",
    "from functions_utils import compounds\n",
    "from functions_utils import file_splitter\n",
    "from functions_utils import load_output\n",
    "\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "import pyro.distributions as dist\n",
    "import pyro.ops.stats as stats\n",
    "\n",
    "import torch\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f49ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''!!!TO RUN ONLY ONCE!!! when there is no files in splitted_data'''   \n",
    "file_splitter(\"xyz_files/c6h6.xyz\",\"splitted_data\")\n",
    "\n",
    "'''Importing the energies file and storing in variable '''\n",
    "y_input = load_output(\"xyz_files/energies_benzene.xyz\")\n",
    "\n",
    "'''Getting coulomb matrix from each generated file from folder splitted_data'''\n",
    "x_input=compounds(\"splitted_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4641f9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input dataset: (9000, 78)\n"
     ]
    }
   ],
   "source": [
    "x_input= np.array([mol.representation for mol in compounds(\"splitted_data\")])\n",
    "x=x_input[:9000]\n",
    "\n",
    "# print(x)\n",
    "x=shuffle(x)\n",
    "print('Shape of input dataset:',x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c48afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input dataset after transposing: torch.Size([78, 9000])\n"
     ]
    }
   ],
   "source": [
    "#converting dataset to tensor type from numpy\n",
    "in_data=torch.tensor(x, dtype=torch.get_default_dtype())\n",
    "y=in_data.t()\n",
    "print('Shape of input dataset after transposing:',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe1f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clearing the parameters from previous run\n",
    "pyro.clear_param_store()\n",
    "\n",
    "#Initializing the prior mean\n",
    "X_init=torch.zeros(9000,20)\n",
    "X = Parameter(X_init.clone())\n",
    "#Using exponential kernel for Sparse GP Regression\n",
    "kernel=gp.kernels.Exponential(input_dim=20, lengthscale=torch.ones(20))\n",
    "\n",
    "#Inducing points for Sparse GP Regression\n",
    "Xu= stats.resample(X_init.clone(),800)\n",
    "\n",
    "gplvm=gp.models.SparseGPRegression(X, y, kernel, Xu, jitter=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14ba10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gplvm.X = pyro.nn.PyroSample(dist.Normal(X_init, 0.1).to_event())\n",
    "gplvm.autoguide(\"X\", dist.Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a5f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Uses Adam optimizer and learning rate of 0.01 by default to converge the ELBO loss for increasing likelihood'''\n",
    "loss=gp.util.train(gplvm, num_steps=4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3724ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)\n",
    "plt.xlabel(\"Training size\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(loss)\n",
    "plt.xlabel(\"Training size(log)\")\n",
    "plt.ylabel(\"Loss(log)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276bb3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extracting mean and standard deviation from model in latent space\n",
    "gplvm.mode = \"guide\"\n",
    "mean = gplvm.X_loc.detach().numpy()  \n",
    "std_dev=gplvm.X_scale.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c73bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Used for predicting new latent points'''\n",
    "new_points_latent=np.random.normal(loc=np.mean(mean,axis=0),scale=np.mean(std_dev,axis=0),size=(8000,20))\n",
    "print(\"Shape of predicting new_points in latent space\", new_points_latent.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7337cf",
   "metadata": {},
   "source": [
    "# Using predicted points to predict coulomb matrix using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b58f980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Converting predicted points in tensor'''\n",
    "new_points_latent_tensor=torch.tensor(new_points_latent,dtype=torch.get_default_dtype())\n",
    "\n",
    "'''Using forward method from pyro to convert new predi'''\n",
    "#Xnew is set as gplvm.forward() had it as **kwargs parameter \n",
    "predicted_coulomb_matrix=np.random.normal(gplvm(Xnew=new_points_latent_tensor)[0].detach().numpy(),gplvm(Xnew=new_points_latent_tensor)[1].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40c92dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predicted coulomb matrix (78, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of predicted coulomb matrix\",predicted_coulomb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4156e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"predicted_coulomb_matrix.npy\", predicted_coulomb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55854904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
